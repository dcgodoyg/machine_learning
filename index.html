<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>1. Background</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<p><strong>This document contains the course project for the Machine Learning Course of the</strong>
<strong>Johns Hopkins&#39; Data Science Specialization at Coursera.</strong></p>

<h2>1. Background</h2>

<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to
collect a large amount of data about personal activity relatively inexpensively.
These type of devices are part of the quantified self movement â€“ a group of enthusiasts
who take measurements about themselves regularly to improve their health, to find
patterns in their behavior, or because they are tech geeks. One thing that people
regularly do is quantify how much of a particular activity they do, but they rarely
quantify how well they do it. In this project, the goal is to use data from
accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were
asked to perform barbell lifts correctly and incorrectly in 5 different ways. More
information is available from the website here: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>
(see the section on the Weight Lifting Exercise Dataset). </p>

<h3>1.1. Data</h3>

<p>The training data for this project are available here: </p>

<p><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv</a></p>

<p>The test data are available here: </p>

<p><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv</a></p>

<p>The data for this project come from this source: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a>.</p>

<h2>2. Assignment</h2>

<p>In order to complete the assignment, the followung steps were taken.</p>

<ul>
<li>Load the data</li>
<li>Clean the data</li>
<li>Prepare and Perform a Random Forest Model</li>
<li>Predict resuls of the testing dataset.</li>
</ul>

<h3>2.1. Load the Data</h3>

<p>The files were downloaded from the links provided before. The data was loaded into
two different datasets: <em>trainingfile</em> and <em>testingfile</em>.</p>

<pre><code class="r">trainingfile &lt;- read.csv(trainingfileroute, header=TRUE,
                     na.strings=c(&quot;NA&quot;, &quot;&quot;))
testingfile &lt;- read.csv(testingfileroute, header=TRUE,
                     na.strings=c(&quot;NA&quot;, &quot;&quot;))
</code></pre>

<h3>2.2. Clean the Data</h3>

<p>In order to prepare a good model, I removed data that may not contribute to the
ability to predict of the model. First, I removed variables that identified the
subject of study and the time the data was taken. Then, I removed variables
that contained more than 90% of NAs. Then, I removed data that does not vary
significantly. </p>

<p>Note that the data cleaning process was done to the trainingfile and testinfile
dataset equally. Every process is explained below:</p>

<h4>2.2.1. Removing Identification and Information Variables</h4>

<p>After a quick inspection of the datasets, I noticed that the first six variables
corresponded to identification variables or information variables.  Since these
variables may not add prediction capacitiy to a model, I removed them.</p>

<pre><code class="r">trainingfile &lt;- trainingfile[, -(1:6)]
testingfile &lt;- testingfile[, -(1:6)]
</code></pre>

<h4>2.2.2. Removing Variables Composed Mainly by NAs</h4>

<p>After a quick inspection of the datasets, I noticed that there were many variables
that were composed mainly by NAs (missing data). Since these variables may not
add prediction capacity to a model, I removed them.</p>

<pre><code class="r">minimumrows &lt;- nrow(trainingfile)*0.9
naspercolumn &lt;- sapply(trainingfile, function(x) sum(is.na(x)))
trainingfile &lt;- trainingfile[, naspercolumn &lt; minimumrows]

minimumrows &lt;- nrow(testingfile)*0.9
naspercolumn &lt;- sapply(testingfile, function(x) sum(is.na(x)))
testingfile &lt;- testingfile[, naspercolumn &lt; minimumrows]
</code></pre>

<h4>2.2.3. Removing Low Varying Variables</h4>

<p>After a quick inspection of the datasets, I noticed that there were vaiables that
did not vary much. Since these variables may not add prediction capacity to a model,
I removed them. For doing this, I removed variables which its
<a href="https://en.wikipedia.org/wiki/Coefficient_of_variation">Coefficient of Variation</a>.
was less than 1. </p>

<pre><code class="r">variation &lt;- sapply(trainingfile, function(x) abs(sd(x)/mean(x)))
</code></pre>

<pre><code>## Warning in mean.default(x): argument is not numeric or logical: returning
## NA
</code></pre>

<pre><code class="r">trainingfile &lt;- trainingfile[ , -variation[-length(variation)] &lt; 1]

variation &lt;- sapply(testingfile, function(x) abs(sd(x)/mean(x)))
testingfile &lt;- testingfile[ , -variation[-length(variation)] &lt; 1]
</code></pre>

<h3>2.3. Prepare and Perform and Random Forest Model</h3>

<p>To create a model that can predict the classe certain data belongs to, 
I used the Random Forest algorithm in the training dataset. The reasons I chose
the Random Forest algorithm are:</p>

<ul>
<li>The algorithm does not expect linear features on the variables</li>
<li>The algorithm does not expect lienar relationships among variables</li>
<li>The algorithm maages well large number of training samples</li>
<li>The algorithm gives estimates of what variables are important in the classification</li>
<li>The algorithm there does not need cross-validation as it is estimated internally,
during the execution.</li>
</ul>

<p>In order to prepare the data, I created a training and testing data set out of
the <em>trainingfile</em>.</p>

<h4>2.3.1. Creating the Training and Testing Data Set</h4>

<p>To create the Random Forest algorithm, the data on the trainingfile were split into
two data sets: training and testing.</p>

<pre><code class="r">library(caret)
inTrain &lt;- createDataPartition(trainingfile$classe, p=0.75, list=FALSE)
training &lt;- trainingfile[inTrain, ]
testing &lt;- trainingfile[-inTrain, ]
</code></pre>

<h4>2.3.2. Creating the Random Forest Algorithm</h4>

<p>The random forest algorithm was crated using the randomForest package in R.</p>

<pre><code class="r">library(randomForest)
set.seed(1234)
modelFit &lt;- randomForest(classe~., data=training, importance=TRUE)
</code></pre>

<p>The results of the algorithm were:</p>

<pre><code class="r">modelFit
</code></pre>

<pre><code>## 
## Call:
##  randomForest(formula = classe ~ ., data = training, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 7
## 
##         OOB estimate of  error rate: 0.22%
## Confusion matrix:
##      A    B    C    D    E  class.error
## A 4184    0    0    0    1 0.0002389486
## B    4 2842    2    0    0 0.0021067416
## C    0    8 2559    0    0 0.0031164784
## D    0    0   10 2401    1 0.0045605307
## E    0    0    0    7 2699 0.0025868441
</code></pre>

<p>As the results show, every time we only randomly used 7 predictorts. Additionally,
The error rate is really small.</p>

<h4>2.3.3. Evaluation of the Altogrithm</h4>

<p>To evaluate the algorithm, we will predict the outcome(classe) of the testing dataset
created in section 2.3.1 and evaluate the results using a Confusion Matrix.</p>

<pre><code class="r">confusionMatrix(predict(modelFit, newdata=testing[, -ncol(testing)]),
                testing$classe)
</code></pre>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1395    0    0    0    0
##          B    0  949    2    0    0
##          C    0    0  853    4    0
##          D    0    0    0  800    0
##          E    0    0    0    0  901
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9988          
##                  95% CI : (0.9973, 0.9996)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9985          
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   1.0000   0.9977   0.9950   1.0000
## Specificity            1.0000   0.9995   0.9990   1.0000   1.0000
## Pos Pred Value         1.0000   0.9979   0.9953   1.0000   1.0000
## Neg Pred Value         1.0000   1.0000   0.9995   0.9990   1.0000
## Prevalence             0.2845   0.1935   0.1743   0.1639   0.1837
## Detection Rate         0.2845   0.1935   0.1739   0.1631   0.1837
## Detection Prevalence   0.2845   0.1939   0.1748   0.1631   0.1837
## Balanced Accuracy      1.0000   0.9997   0.9983   0.9975   1.0000
</code></pre>

<p>As the table above shows, the accuracy of the prediction model s pretty good. 
Additionally, the kappa measurement is also very good.</p>

<h3>3. Predicting the Classe of the Testing File</h3>

<p>I predicted the class of the observations that were on the testing file using
the algorithm built in section 2.3.2. </p>

<pre><code class="r">predictions &lt;- predict(modelFit,newdata=testingfile)
predictions
</code></pre>

<pre><code>##  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
##  B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 
## Levels: A B C D E
</code></pre>

<p>The data was used in the Submission of the course project. </p>

<hr>

<p>END</p>

</body>

</html>
